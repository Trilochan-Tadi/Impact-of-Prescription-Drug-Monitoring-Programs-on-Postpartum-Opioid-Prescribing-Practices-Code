{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique male IDs in the 'pat_id' column: 144457\n",
      "Total number of unique female IDs in the 'pat_id' column: 4891514\n",
      "Total number of unique IDs with missing or unexpected values in the 'der_sex' column: 367\n"
     ]
    }
   ],
   "source": [
    "#### 1 explore and find how many female,male and or other unknown\n",
    "\n",
    "import pandas as pd\n",
    "file_path = r\"Z:\\chelsea\\datalake\\update_7\\claims_usa_age.csv\" \n",
    "unique_male_ids = set()\n",
    "unique_female_ids = set()\n",
    "unexpected_gender_ids = set()\n",
    "\n",
    "for chunk in pd.read_csv(file_path, usecols=['pat_id', 'der_sex'], chunksize=1000000):\n",
    "    unique_male_ids.update(chunk[chunk['der_sex'] == 'M']['pat_id'].unique())\n",
    "    \n",
    "    unique_female_ids.update(chunk[chunk['der_sex'] == 'F']['pat_id'].unique())\n",
    "   \n",
    "   # Identify rows where 'der_sex' is missing, empty, or contains unexpected values\n",
    "    unexpected_chunk = chunk[chunk['der_sex'].isna() | (chunk['der_sex'] == '') | (~chunk['der_sex'].isin(['M', 'F']))]\n",
    "    \n",
    "    # Add unique 'pat_id's with missing or unexpected 'der_sex' values to the set\n",
    "    unexpected_gender_ids.update(unexpected_chunk['pat_id'].unique())\n",
    "\n",
    "\n",
    "total_unique_male_ids = len(unique_male_ids)\n",
    "total_unique_female_ids = len(unique_female_ids)\n",
    "total_unexpected_gender_ids = len(unexpected_gender_ids)\n",
    "\n",
    "print(f\"Total number of unique male IDs in the 'pat_id' column: {total_unique_male_ids}\")\n",
    "print(f\"Total number of unique female IDs in the 'pat_id' column: {total_unique_female_ids}\")\n",
    "print(f\"Total number of unique IDs with missing or unexpected values in the 'der_sex' column: {total_unexpected_gender_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File with all columns for female patients has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "### Creating a new file to only include Female patients \n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "## File paths \n",
    "input_file_path = r\"Z:\\chelsea\\datalake\\update_7\\claims_usa_age.csv\"\n",
    "output_file_path = r\"Z:\\chelsea\\datalake\\New_cohort\\claims_usa_females.csv\"\n",
    "\n",
    "## createing teh oupt file\n",
    "os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "chunksize = 100000\n",
    "for chunk in pd.read_csv(input_file_path, chunksize=chunksize,low_memory=False):\n",
    "    # Filter for female patients ('F' in 'der_sex' column)\n",
    "    female_chunk = chunk[chunk['der_sex'] == 'F']\n",
    "\n",
    "    # Write the filtered chunk to the new output file\n",
    "    if not female_chunk.empty:\n",
    "        if os.path.exists(output_file_path):\n",
    "            female_chunk.to_csv(output_file_path, mode='a', index=False, header=False)\n",
    "        else:\n",
    "            female_chunk.to_csv(output_file_path, mode='w', index=False, header=True)\n",
    "\n",
    "print(\"File with all columns for female patients has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique male IDs in the 'pat_id' column: 0\n",
      "Total number of unique female IDs in the 'pat_id' column: 4891514\n",
      "Total number of unique IDs with missing or unexpected values in the 'der_sex' column: 0\n"
     ]
    }
   ],
   "source": [
    "# checking the output file for any males or unkow values \n",
    "\n",
    "import pandas as pd\n",
    "file_path = r\"Z:\\chelsea\\datalake\\New_cohort\\claims_usa_females.csv\"\n",
    "unique_male_ids = set()\n",
    "unique_female_ids = set()\n",
    "unexpected_gender_ids = set()\n",
    "\n",
    "for chunk in pd.read_csv(file_path, usecols=['pat_id', 'der_sex'], chunksize=1000000):\n",
    "    unique_male_ids.update(chunk[chunk['der_sex'] == 'M']['pat_id'].unique())\n",
    "    \n",
    "    unique_female_ids.update(chunk[chunk['der_sex'] == 'F']['pat_id'].unique())\n",
    "   \n",
    "   # Identify rows where 'der_sex' is missing, empty, or contains unexpected values\n",
    "    unexpected_chunk = chunk[chunk['der_sex'].isna() | (chunk['der_sex'] == '') | (~chunk['der_sex'].isin(['M', 'F']))]\n",
    "    \n",
    "    # Add unique 'pat_id's with missing or unexpected 'der_sex' values to the set\n",
    "    unexpected_gender_ids.update(unexpected_chunk['pat_id'].unique())\n",
    "\n",
    "\n",
    "total_unique_male_ids = len(unique_male_ids)\n",
    "total_unique_female_ids = len(unique_female_ids)\n",
    "total_unexpected_gender_ids = len(unexpected_gender_ids)\n",
    "\n",
    "print(f\"Total number of unique male IDs in the 'pat_id' column: {total_unique_male_ids}\")\n",
    "print(f\"Total number of unique female IDs in the 'pat_id' column: {total_unique_female_ids}\")\n",
    "print(f\"Total number of unique IDs with missing or unexpected values in the 'der_sex' column: {total_unexpected_gender_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Titles:\n",
      "Index(['pat_id', 'claimno', 'ndc', 'dayssup', 'quan', 'from_dt', 'to_dt',\n",
      "       'diag1', 'diag2', 'diag3', 'diag4', 'diag5', 'diag6', 'diag7', 'diag8',\n",
      "       'diag9', 'diag10', 'diag11', 'diag12', 'month_id', 'icdprc1', 'icdprc2',\n",
      "       'icdprc3', 'icdprc4', 'der_sex', 'der_yob', 'pat_region', 'pat_state',\n",
      "       'pat_Zip3', 'year_of_claim', 'month_of_claim', 'pat_age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "##### Checking the coloumn names \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "file_path = r\"Z:\\chelsea\\datalake\\New_cohort\\claims_usa_females.csv\"\n",
    "\n",
    "# Define the chunk size (e.g., 100,000 rows at a time)\n",
    "chunksize = 100000\n",
    "\n",
    "# Initialize an empty list to store the column names\n",
    "column_names = None\n",
    "\n",
    "# Read the file in chunks\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize, low_memory=False):\n",
    "    column_names = chunk.columns  # Get column names from the first chunk\n",
    "    break  # Stop after the first chunk since we only need column names\n",
    "\n",
    "print(\"Column Titles:\")\n",
    "print(column_names)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3de59ade2ee4eabf8d6554090db31bdd94608df00f05391c2d316a7da62ee3f6"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
