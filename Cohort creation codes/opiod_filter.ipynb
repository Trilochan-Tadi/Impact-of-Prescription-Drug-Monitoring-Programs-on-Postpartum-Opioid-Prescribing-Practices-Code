{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In This file we filter out pateint that are not opioid naivee. Meaning pateint how have opioid claim 90 days prior to delivery and checks for teh pateints with opioid use in the 7 days after delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "from pandas._libs.tslibs.parsing import DateParseError\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndc_file_path = r\"Z:\\chelsea\\datalake\\final_codes\\ndc_opioids_codes.csv\"  # Replace this with the actual path to your NDC codes CSV file\n",
    "\n",
    "opioid_codes_df = pd.read_csv(ndc_file_path, dtype={\"ndc\": str})\n",
    "ndc_codes = opioid_codes_df['ndc'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = r\"Z:\\chelsea\\datalake\\New_cohort\\90day_day_filter.csv\"\n",
    "output_file_path = r\"Z:/chelsea/datalake/New_cohort/New_filters/opioid_info.csv\"  \n",
    "ndc_codes_path = r\"Z:/chelsea/datalake/final_codes/ndc_opioids_codes.csv\"\n",
    "\n",
    "# Load NDC codes for opioid prescriptions\n",
    "ndc_codes_df = pd.read_csv(ndc_codes_path)\n",
    "ndc_codes = ndc_codes_df['ndc'].tolist()\n",
    "\n",
    "# Function to identify opioid dates and relevant information\n",
    "def identify_opioids_dates(dataframe: pd.DataFrame, ndc_codes: list,\n",
    "                           pat_id_p: str = 'pat_id_p',\n",
    "                           ndc: str = \"ndc\", \n",
    "                           from_dt: str = \"from_dt\",\n",
    "                           quan: str = \"quan\",\n",
    "                           dayssup: str = \"dayssup\",\n",
    "                           opioid_dts: str = \"opioid_dates\",\n",
    "                           presc_opioid: str = \"presc_opioid\",\n",
    "                           op_dayssup: str = \"op_dayssup\",\n",
    "                           op_quan: str = \"op_quan\"):\n",
    "                           \n",
    "    grouped_df = dataframe.groupby(by=pat_id_p)\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    for pat_id, group in grouped_df:\n",
    "        opioid_dates = group.loc[group[ndc].isin(ndc_codes), from_dt]\n",
    "        opioid_dates = opioid_dates.tolist() if not opioid_dates.empty else []\n",
    "        \n",
    "        opioid_presc = group.loc[group[ndc].isin(ndc_codes), ndc]\n",
    "        opioid_presc = opioid_presc.tolist() if not opioid_presc.empty else []\n",
    "        \n",
    "        opioid_quan = group.loc[group[ndc].isin(ndc_codes), quan]\n",
    "        opioid_quan = opioid_quan.tolist() if not opioid_quan.empty else []\n",
    "        \n",
    "        opioid_ds = group.loc[group[ndc].isin(ndc_codes), dayssup]\n",
    "        opioid_ds = opioid_ds.tolist() if not opioid_ds.empty else []\n",
    "\n",
    "        # Create a DataFrame for the current patient's opioid information\n",
    "        patient_result_df = pd.DataFrame({\n",
    "            pat_id_p: [pat_id], \n",
    "            opioid_dts: [opioid_dates], \n",
    "            presc_opioid: [opioid_presc], \n",
    "            op_dayssup: [opioid_ds], \n",
    "            op_quan: [opioid_quan]\n",
    "        })\n",
    "        \n",
    "        result_df = pd.concat([result_df, patient_result_df])\n",
    "    \n",
    "    # Merge back with the original dataframe\n",
    "    result_df = pd.merge(dataframe, result_df, on=pat_id_p, how='left')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# Function to process chunks and create opioid dates\n",
    "def process_chunks_and_create_opioid_dates(input_file, output_file, ndc_codes, chunk_size=5000):\n",
    "    processed_patients = 0\n",
    "    processed_chunks = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with pd.read_csv(input_file, chunksize=chunk_size) as reader:\n",
    "        for chunk_idx, chunk_df in enumerate(reader):\n",
    "            print(f\"\\nProcessing chunk {chunk_idx + 1}\")\n",
    "            try:\n",
    "                # Identify opioid dates\n",
    "                chunk_df_with_opioid_dates = identify_opioids_dates(chunk_df, ndc_codes)\n",
    "\n",
    "                # Append results to the output file\n",
    "                chunk_df_with_opioid_dates.to_csv(output_file, mode='a', index=False, header=(chunk_idx == 0))\n",
    "\n",
    "                # Track the number of processed patients\n",
    "                processed_patients += len(chunk_df_with_opioid_dates)\n",
    "                processed_chunks += 1\n",
    "\n",
    "                print(f\"Processed patients: {processed_patients}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk {chunk_idx + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Total processing time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Process the file in chunks and create opioid dates\n",
    "process_chunks_and_create_opioid_dates(input_file_path, output_file_path, ndc_codes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check opioid use in the 90 days prior to delivery and create a column\n",
    "def check_opioid_in_pregnancy(df: pd.DataFrame, pat_id_p='pat_id_p', delivery_dt='delivery_dt', opioid_dates_col='opioid_dates'):\n",
    "    df['opioid_in_pregnancy'] = 'No'\n",
    "\n",
    "    for pat_id, group_df in df.groupby(pat_id_p):\n",
    "        delivery_date = pd.to_datetime(group_df[delivery_dt].iloc[0])\n",
    "        delivery_dt_90 = delivery_date - pd.Timedelta(days=90)\n",
    "\n",
    "        # Parse the opioid dates\n",
    "        opioid_dates = group_df[opioid_dates_col].iloc[0]\n",
    "        if not pd.isna(opioid_dates):\n",
    "            opioid_dates = [pd.to_datetime(date.strip(\"[Timestramp('')]\")) for date in opioid_dates.split(\", \")]\n",
    "\n",
    "            # Check if any opioid use falls within the 90-day period before delivery\n",
    "            if any(delivery_dt_90 <= date <= delivery_date for date in opioid_dates):\n",
    "                df.loc[group_df.index, 'opioid_in_pregnancy'] = 'Yes'\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to check opioid use in the 7 days after delivery and create a column\n",
    "def check_opioid_after_delivery(df: pd.DataFrame, pat_id_p='pat_id_p', delivery_dt='delivery_dt', opioid_dates_col='opioid_dates'):\n",
    "    df['opioid_after_delivery'] = 'No'\n",
    "\n",
    "    for pat_id, group_df in df.groupby(pat_id_p):\n",
    "        delivery_date = pd.to_datetime(group_df[delivery_dt].iloc[0])\n",
    "        delivery_dt_7 = delivery_date + pd.Timedelta(days=7)\n",
    "\n",
    "        # Parse the opioid dates\n",
    "        opioid_dates = group_df[opioid_dates_col].iloc[0]\n",
    "        if not pd.isna(opioid_dates):\n",
    "            opioid_dates = [pd.to_datetime(date.strip(\"[Timestramp('')]\")) for date in opioid_dates.split(\", \")]\n",
    "\n",
    "            # Check if any opioid use falls within the 7-day period after delivery\n",
    "            if any(delivery_date <= date <= delivery_dt_7 for date in opioid_dates):\n",
    "                df.loc[group_df.index, 'opioid_after_delivery'] = 'Yes'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_file_path = r\"Z:\\chelsea\\datalake\\New_cohort\\New_filters\\opioid_info.csv\"\n",
    "output_file_path = r\"Z:\\chelsea\\datalake\\New_cohort\\New_filters\\opioid_in_pregnancy.csv\"\n",
    "chunk_size = 10000\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# Function to check opioid use in the 90 days prior to delivery\n",
    "def check_opioid_in_pregnancy(chunk_df, pat_id_p='pat_id_p', delivery_dt='delivery_dt', opioid_dates_col='opioid_dates'):\n",
    "    chunk_df['opioid_in_pregnancy'] = 'No'  # Default to \"No\" (no opioid use in pregnancy period)\n",
    "\n",
    "    for pat_id, group_df in chunk_df.groupby(pat_id_p):\n",
    "        delivery_date = pd.to_datetime(group_df[delivery_dt].iloc[0], errors='coerce')\n",
    "        \n",
    "        if pd.notna(delivery_date):\n",
    "            delivery_dt_90 = delivery_date - pd.Timedelta(days=90)\n",
    "\n",
    "            # Parse opioid dates\n",
    "            opioid_dates = group_df[opioid_dates_col].iloc[0]\n",
    "            if not pd.isna(opioid_dates):\n",
    "                opioid_dates = [pd.to_datetime(date.strip(\"[Timestramp('')]\"), errors='coerce') for date in opioid_dates.split(\", \")]\n",
    "                \n",
    "                # If any opioid use falls within the 90-day period, set \"Yes\"\n",
    "                if any(pd.notna(date) and delivery_dt_90 <= date <= delivery_date for date in opioid_dates):\n",
    "                    chunk_df.loc[group_df.index, 'opioid_in_pregnancy'] = 'Yes'\n",
    "\n",
    "    return chunk_df\n",
    "\n",
    "# Function to check opioid use in the 7 days after delivery\n",
    "def check_opioid_after_delivery(chunk_df, pat_id_p='pat_id_p', delivery_dt='delivery_dt', opioid_dates_col='opioid_dates'):\n",
    "    chunk_df['opioid_after_delivery'] = 'No'  # Default to \"No\" (no opioid use after delivery period)\n",
    "\n",
    "    for pat_id, group_df in chunk_df.groupby(pat_id_p):\n",
    "        delivery_date = pd.to_datetime(group_df[delivery_dt].iloc[0], errors='coerce')\n",
    "        \n",
    "        if pd.notna(delivery_date):\n",
    "            delivery_dt_7 = delivery_date + pd.Timedelta(days=7)\n",
    "\n",
    "            # Parse opioid dates\n",
    "            opioid_dates = group_df[opioid_dates_col].iloc[0]\n",
    "            if not pd.isna(opioid_dates):\n",
    "                opioid_dates = [pd.to_datetime(date.strip(\"[Timestramp('')]\"), errors='coerce') for date in opioid_dates.split(\", \")]\n",
    "\n",
    "                # If any opioid use is found within 0 to 7 days, set \"Yes\"\n",
    "                # If any opioid use is found beyond 7 days, set \"No\"\n",
    "                if any(pd.notna(date) and delivery_date <= date <= delivery_dt_7 for date in opioid_dates):\n",
    "                    chunk_df.loc[group_df.index, 'opioid_after_delivery'] = 'Yes'\n",
    "                elif any(pd.notna(date) and date > delivery_dt_7 for date in opioid_dates):\n",
    "                    chunk_df.loc[group_df.index, 'opioid_after_delivery'] = 'No'\n",
    "                    \n",
    "    return chunk_df\n",
    "\n",
    "# Function to process each chunk and filter based on both conditions\n",
    "def process_chunk(chunk_df):\n",
    "    # First, check for opioids in the 90 days prior to delivery\n",
    "    chunk_df = check_opioid_in_pregnancy(chunk_df)\n",
    "    # Then, check for opioids in the 7 days after delivery\n",
    "    chunk_df = check_opioid_after_delivery(chunk_df)\n",
    "    \n",
    "    # Include only patients with \"No\" in opioid_in_pregnancy and \"Yes\" in opioid_after_delivery\n",
    "    filtered_chunk = chunk_df[(chunk_df['opioid_in_pregnancy'] == 'No') & (chunk_df['opioid_after_delivery'] == 'Yes')]\n",
    "    \n",
    "    return filtered_chunk\n",
    "\n",
    "# Function to process each chunk and track progress\n",
    "def process_data_sequentially():\n",
    "    total_chunks = sum(1 for _ in pd.read_csv(input_file_path, chunksize=chunk_size))\n",
    "    processed_chunks = 0\n",
    "\n",
    "    with pd.read_csv(input_file_path, chunksize=chunk_size) as reader:\n",
    "        for chunk_idx, chunk_df in enumerate(reader):\n",
    "            print(f\"\\nProcessing chunk {chunk_idx + 1} of {total_chunks}\")\n",
    "            \n",
    "            # Process the chunk\n",
    "            filtered_chunk = process_chunk(chunk_df)\n",
    "            \n",
    "            # Append results to the output file\n",
    "            mode = 'a' if chunk_idx > 0 else 'w'\n",
    "            filtered_chunk.to_csv(output_file_path, mode=mode, index=False, header=(chunk_idx == 0))\n",
    "\n",
    "            # Track progress\n",
    "            processed_chunks += 1\n",
    "            elapsed_time = time.time() - start_time\n",
    "            estimated_time_remaining = (total_chunks - processed_chunks) * (elapsed_time / processed_chunks)\n",
    "\n",
    "            # Convert estimated time remaining to HH:MM:SS\n",
    "            hours, rem = divmod(estimated_time_remaining, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            progress_percentage = (processed_chunks / total_chunks) * 100\n",
    "\n",
    "            # Display progress\n",
    "            print(f\"Chunk {chunk_idx + 1}/{total_chunks} processed\")\n",
    "            print(f\"Total elapsed time: {elapsed_time:.2f} seconds\")\n",
    "            print(f\"Estimated time remaining: {int(hours):02}:{int(minutes):02}:{int(seconds):02}\")\n",
    "            print(f\"Progress: {progress_percentage:.2f}%\")\n",
    "\n",
    "    total_elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nTotal processing time: {total_elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Run the main processing function\n",
    "process_data_sequentially()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03eb0f413ac8a21b237757e6c01d7f64cf7b4655952acb378d042bd2774cacd1"
  },
  "kernelspec": {
   "display_name": "Python 3.11.7 ('Isabel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
