{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Book will used to Calaculate the total pregnaices and establish the protcol for multiple pregainces and for the future cohort\n",
    "\n",
    "### 1.A Full Pregengancy is if the diagonosi coloumsn have at least have  one of the delivery codes \n",
    "### 2.Determine the total number of procedures for each patient.\n",
    "##  3.First by identifying pregeancy events and checking the time intervals between consecutive diagnosis intervals greater than 210 days will be considered a separate event "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step one find the total  pregeancy for each patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libaries \n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pandas._libs.tslibs.parsing import DateParseError\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load delivery-related diagnosis codes\n",
    "delivery_codes_path = r\"Z:\\chelsea\\datalake\\final_codes\\delivery_codes.csv\"\n",
    "delivery_codes_df = pd.read_csv(delivery_codes_path)\n",
    "delivery_codes = delivery_codes_df['dx_cd'].tolist()\n",
    "\n",
    "# Load pregnancy-related diagnosis codes\n",
    "pregnancy_codes_path = r\"Z:\\chelsea\\datalake\\final_codes\\pregnancy_code.csv\"\n",
    "pregnancy_codes_df = pd.read_csv(pregnancy_codes_path)\n",
    "pregnancy_codes = pregnancy_codes_df['dx_cd'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_total_pregnancies(df: pd.DataFrame,\n",
    "                                delivery_codes: list,\n",
    "                                pregnancy_codes: list,\n",
    "                                pat_id: str = 'pat_id',\n",
    "                                from_dt_col: str = 'from_dt',\n",
    "                                to_dt_col: str = 'to_dt',\n",
    "                                total_pregs: str = 'total_pregnancies',\n",
    "                                dts_pregs: str = 'dts_pregnancies'):\n",
    "    \"\"\"\n",
    "    Function to calculate total pregnancies for each patient.\n",
    "    This function reruns patients if multiple pregnancies are detected.\n",
    "    Now checks both delivery and pregnancy-related diagnosis codes.\n",
    "    \"\"\"\n",
    "    # Convert the date columns to datetime format\n",
    "    df[from_dt_col] = pd.to_datetime(df[from_dt_col], errors='coerce')\n",
    "    df[to_dt_col] = pd.to_datetime(df[to_dt_col], errors='coerce')\n",
    "\n",
    "    # Sort by patient ID and diagnosis date\n",
    "    df = df.sort_values(by=[pat_id, from_dt_col])\n",
    "\n",
    "    # Initialize columns for storing pregnancy information\n",
    "    df[total_pregs] = 0\n",
    "    df[dts_pregs] = None\n",
    "\n",
    "    # Identify if any diagnosis code is in the list of delivery or pregnancy codes\n",
    "    diag_cols = [f'diag{i}' for i in range(1, 13)]  # diag1 ... diag12\n",
    "    all_codes = set(delivery_codes) | set(pregnancy_codes)  # union of both lists\n",
    "    df['any_diag_in_dx_codes'] = df[diag_cols].isin(all_codes).any(axis=1)\n",
    "\n",
    "    # Filter only rows where diagnosis codes are present and dates are valid\n",
    "    df = df[df['any_diag_in_dx_codes'] & df[from_dt_col].notnull()]\n",
    "\n",
    "    # Process each patient group to determine pregnancies\n",
    "    for patient_id, group in df.groupby(pat_id):\n",
    "        selected_rows = group[group['any_diag_in_dx_codes']]  # rows with delivery/pregnancy codes\n",
    "        preg_dt = []\n",
    "\n",
    "        if not selected_rows.empty:\n",
    "            # Take the first date as initial pregnancy\n",
    "            first_preg = selected_rows.iloc[0][from_dt_col]\n",
    "            preg_dt.append(first_preg)\n",
    "            num_pregnancies = 1\n",
    "\n",
    "            # Calculate intervals between diagnosis dates to detect new pregnancies\n",
    "            intervals = selected_rows[from_dt_col].diff().dt.days\n",
    "            new_pregnancies = intervals > 210\n",
    "            num_pregnancies += new_pregnancies.sum()\n",
    "            preg_dt.extend(selected_rows[new_pregnancies][from_dt_col])\n",
    "\n",
    "            # Update DataFrame with results\n",
    "            df.loc[df[pat_id] == patient_id, total_pregs] = num_pregnancies\n",
    "            df.loc[df[pat_id] == patient_id, dts_pregs] = ','.join(map(str, preg_dt))\n",
    "\n",
    "    # Drop the helper column\n",
    "    df.drop(columns=['any_diag_in_dx_codes'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Function to process pregnancies for patients across chunks\n",
    "def process_pregnancies(df: pd.DataFrame, pat_id: str = 'pat_id', total_pregs: str = \"total_pregnancies\", \n",
    "                        pat_id_p: str = \"pat_id_p\", del_dt: str = \"delivery_dt\", dts_pregs: str = 'dts_pregnancies'):\n",
    "    result_df = pd.DataFrame()\n",
    "    groups_pat_id = df.groupby(pat_id)\n",
    "    for patient_id, group in groups_pat_id:\n",
    "        number_pregnancies = int(group[total_pregs].max())\n",
    "        for i in range(1, number_pregnancies + 1):\n",
    "            group[pat_id_p] = group[pat_id] + '_' + str(i)\n",
    "            group[del_dt] = group[dts_pregs].apply(lambda x: x.split(',')[i - 1] if pd.notnull(x) else None)\n",
    "\n",
    "            result_df = pd.concat([result_df, group], ignore_index=True)\n",
    "    return result_df\n",
    "\n",
    "# Function for formating dates\n",
    "def format_date_cols (data:pd.DataFrame, col: str):\n",
    "    \"\"\"This function converts a column to datetime format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        dataframe to be manipulated.\n",
    "    col : str\n",
    "        column to be converted to datetime format.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pd.DataFrame\n",
    "        dataframe with the column converted to datetime format.\n",
    "    \"\"\"\n",
    "    data[col] = pd.to_datetime(data[col], infer_datetime_format=True, format ='mixed', errors='coerce')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output paths\n",
    "input_file_path = r\"Z:\\chelsea\\datalake\\New_cohort\\claims_usa_females.csv\"\n",
    "output_file_initial = r\"Z:\\chelsea\\datalake\\New_cohort\\pregnancy_identified.csv\"  \n",
    "output_file_fixed = r\"Z:\\chelsea\\datalake\\New_cohort\\pregnancy_corrected.csv\"    \n",
    "output_file_final = r\"Z:\\chelsea\\datalake\\New_cohort\\pregnancy_processed.csv\"    \n",
    "\n",
    "chunksize = 100000\n",
    "total_patients_identified = 0\n",
    "complete_info_patients = 0\n",
    "incomplete_info_patients = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Process data to create pregnancy_identified.csv\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "chunksize = 100000  \n",
    "processed_patients = set()\n",
    "\n",
    "start_time = time.time()  \n",
    "total_patients_identified = 0\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "for chunk_idx, chunk_df in enumerate(pd.read_csv(input_file_path, dtype=str, chunksize=chunksize)):\n",
    "\n",
    "    try:\n",
    "        # Track start time for the current chunk\n",
    "        chunk_start_time = time.time()\n",
    "\n",
    "        # Convert date columns to datetime\n",
    "        chunk_df['from_dt'] = pd.to_datetime(chunk_df['from_dt'], errors='coerce')\n",
    "        chunk_df['to_dt'] = pd.to_datetime(chunk_df['to_dt'], errors='coerce')\n",
    "\n",
    "        # Filter out rows where dates are not valid\n",
    "        chunk_df = chunk_df[chunk_df['from_dt'].notnull() & chunk_df['to_dt'].notnull()]\n",
    "\n",
    "        # Calculate pregnancies for the chunk\n",
    "        chunk_df = calculate_total_pregnancies(chunk_df, delivery_codes, 'pat_id', 'from_dt', 'to_dt', 'total_pregnancies', 'dts_pregs')\n",
    "        chunk_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Identify patients with multiple pregnancies for rerun\n",
    "        count = chunk_df.groupby('pat_id').agg({'total_pregnancies': 'unique'})\n",
    "        count = count.reset_index()\n",
    "        mask = count['total_pregnancies'].apply(len) > 1\n",
    "        pat_ids = count.loc[mask, 'pat_id'].tolist()\n",
    "\n",
    "        # Reprocess patients with multiple pregnancies\n",
    "        rerun_patients = chunk_df[chunk_df['pat_id'].isin(pat_ids)]\n",
    "        rerun_patients = calculate_total_pregnancies(rerun_patients, delivery_codes, 'pat_id', 'from_dt', 'to_dt', 'total_pregnancies', 'dts_pregs')\n",
    "\n",
    "        # Replace the original rows for these patients with the rerun results\n",
    "        chunk_df = chunk_df[~chunk_df['pat_id'].isin(pat_ids)]\n",
    "        chunk_df = pd.concat([chunk_df, rerun_patients])\n",
    "\n",
    "        # Count patients identified in this chunk\n",
    "        patients_in_chunk = chunk_df['pat_id'].nunique()\n",
    "        total_patients_identified += patients_in_chunk\n",
    "\n",
    "        # Save the processed chunk\n",
    "        if chunk_idx == 0:\n",
    "            chunk_df.to_csv(output_file_initial, mode='w', index=False)\n",
    "        else:\n",
    "            chunk_df.to_csv(output_file_initial, mode='a', index=False, header=False)\n",
    "\n",
    "        # Track the elapsed time for the current chunk\n",
    "        chunk_elapsed_time = time.time() - chunk_start_time\n",
    "        total_elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Calculate estimated time remaining\n",
    "        avg_time_per_chunk = total_elapsed_time / (chunk_idx + 1)\n",
    "        total_chunks_estimate = sum(1 for _ in open(input_file_path)) // chunksize + 1\n",
    "        estimated_time_remaining = avg_time_per_chunk * (total_chunks_estimate - (chunk_idx + 1))\n",
    "\n",
    "        # Print time tracking information\n",
    "        print(f\"Processed chunk {chunk_idx + 1}/{total_chunks_estimate}\")\n",
    "        print(f\"Time elapsed for chunk: {chunk_elapsed_time:.2f} seconds\")\n",
    "        print(f\"Total time elapsed: {total_elapsed_time:.2f} seconds\")\n",
    "        print(f\"Estimated time remaining: {estimated_time_remaining / 60:.2f} minutes\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception found in chunk {chunk_idx}: {str(e)}\")\n",
    "        pass\n",
    "\n",
    "# Final output\n",
    "print(f\"Total number of patients identified: {total_patients_identified}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Process for pregnancy_corrected.csv\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "chunksize = 500000  # Adjust the chunk size as needed\n",
    "\n",
    "# Initialize variables for tracking\n",
    "complete_info_patients = 0\n",
    "incomplete_info_patients = 0\n",
    "start_time = time.time()  # Start time for tracking\n",
    "\n",
    "# Calculate the total number of rows for estimating total chunks\n",
    "total_rows = sum(1 for _ in open(output_file_fixed))  # Total number of rows\n",
    "total_chunks = total_rows // chunksize + 1  # Calculate total chunks\n",
    "\n",
    "# Process for pregnancy_corrected.csv\n",
    "for chunk_idx, chunk_df in enumerate(pd.read_csv(output_file_fixed, dtype=str, chunksize=chunksize)):\n",
    "\n",
    "    # Convert date columns to datetime format\n",
    "    chunk_df['from_dt'] = pd.to_datetime(chunk_df['from_dt'], errors='coerce')\n",
    "    chunk_df['to_dt'] = pd.to_datetime(chunk_df['to_dt'], errors='coerce')\n",
    "\n",
    "    # Filter out rows with invalid dates\n",
    "    chunk_df = chunk_df[chunk_df['from_dt'].notnull() & chunk_df['to_dt'].notnull()]\n",
    "\n",
    "    # Calculate total pregnancies\n",
    "    chunk_df = calculate_total_pregnancies(chunk_df, delivery_codes, 'pat_id', 'from_dt', 'to_dt', 'total_pregnancies', 'dts_pregnancies')\n",
    "    chunk_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Identify patients with incomplete pregnancy information\n",
    "    chunk_df['is_complete_info'] = chunk_df.apply(\n",
    "        lambda x: len(x['dts_pregnancies'].split(',')) == int(x['total_pregnancies']) if pd.notnull(x['dts_pregnancies']) else False, axis=1\n",
    "    )\n",
    "\n",
    "    complete_info_patients += chunk_df[chunk_df['is_complete_info'] == True].shape[0]\n",
    "    incomplete_info_patients += chunk_df[chunk_df['is_complete_info'] == False].shape[0]\n",
    "\n",
    "    # Save to pregnancy_corrected.csv (output_file_fixed)\n",
    "    if chunk_idx == 0:\n",
    "        chunk_df.to_csv(output_file_fixed, mode='w', index=False)\n",
    "    else:\n",
    "        chunk_df.to_csv(output_file_fixed, mode='a', index=False, header=False)\n",
    "\n",
    "    # Time tracking and progress reporting\n",
    "    elapsed_time = time.time() - start_time\n",
    "    processed_chunks = chunk_idx + 1\n",
    "    avg_time_per_chunk = elapsed_time / processed_chunks\n",
    "    remaining_chunks = total_chunks - processed_chunks\n",
    "    estimated_time_remaining = avg_time_per_chunk * remaining_chunks\n",
    "\n",
    "    print(f\"Processed chunk {processed_chunks}/{total_chunks}\")\n",
    "    print(f\"Time elapsed: {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Estimated time remaining: {estimated_time_remaining / 60:.2f} minutes\")\n",
    "\n",
    "# Final output\n",
    "print(f\"Number of patients with complete pregnancy information: {complete_info_patients}\")\n",
    "print(f\"Number of patients with incomplete pregnancy information: {incomplete_info_patients}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Process for pregnancy_processed.csv\n",
    "chunksize = 500000\n",
    "total_patients_processed = 0\n",
    "total_pregnancies = 0\n",
    "\n",
    "# Determine if the output file already exists and load processed patients if it does\n",
    "if os.path.exists(output_file_final):\n",
    "    processed_df = pd.read_csv(output_file_final, usecols=['pat_id'])\n",
    "    total_patients_processed = processed_df['pat_id'].nunique()\n",
    "    print(f\"Resuming from last processed point. Already processed patients: {total_patients_processed}\")\n",
    "    processed_patients = set(processed_df['pat_id'].unique())  # Get the list of already processed patient IDs\n",
    "else:\n",
    "    processed_patients = set()\n",
    "\n",
    "# Calculate total rows and total chunks for estimation\n",
    "total_rows = sum(1 for _ in open(output_file_fixed))\n",
    "total_chunks = total_rows // chunksize\n",
    "\n",
    "# Start time for tracking\n",
    "start_time = time.time()  # Start time for tracking the entire process\n",
    "\n",
    "# Read chunks from the corrected file and continue processing\n",
    "for chunk_idx, chunk_df in enumerate(pd.read_csv(output_file_fixed, chunksize=chunksize)):\n",
    "    # Track the start time of processing the current chunk\n",
    "    chunk_start_time = time.time()\n",
    "\n",
    "    # Filter out patients that are already processed\n",
    "    chunk_df = chunk_df[~chunk_df['pat_id'].isin(processed_patients)]\n",
    "\n",
    "    if chunk_df.empty:  # If the chunk is empty, skip\n",
    "        continue\n",
    "\n",
    "    # Only process patients with at least one pregnancy\n",
    "    chunk_df = chunk_df[chunk_df['total_pregnancies'] != 0]\n",
    "\n",
    "    # Process pregnancies for each patient\n",
    "    chunk_df = process_pregnancies(chunk_df)\n",
    "    chunk_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Count total patients and pregnancies in this chunk\n",
    "    total_patients_processed += chunk_df['pat_id'].nunique()\n",
    "    total_pregnancies += chunk_df[chunk_df['pat_id_p'].notnull()].shape[0]  # Count all non-null pregnancy identifiers\n",
    "\n",
    "    # Save to pregnancy_processed.csv\n",
    "    if os.path.exists(output_file_final):\n",
    "        chunk_df.to_csv(output_file_final, mode='a', index=False, header=False)\n",
    "    else:\n",
    "        chunk_df.to_csv(output_file_final, mode='w', index=False)\n",
    "\n",
    "    # Calculate time taken to process the current chunk\n",
    "    chunk_elapsed_time = time.time() - chunk_start_time\n",
    "    print(f\"Chunk {chunk_idx + 1}/{total_chunks} processed in {chunk_elapsed_time:.2f} seconds.\")\n",
    "\n",
    "    # Calculate and display total progress and time estimation\n",
    "    elapsed_time = time.time() - start_time\n",
    "    processed_chunks = chunk_idx + 1\n",
    "    avg_time_per_chunk = elapsed_time / processed_chunks\n",
    "    remaining_chunks = total_chunks - processed_chunks\n",
    "    estimated_time_remaining = avg_time_per_chunk * remaining_chunks\n",
    "\n",
    "    print(f\"Total processed: {processed_chunks}/{total_chunks} chunks.\")\n",
    "    print(f\"Time elapsed: {elapsed_time:.2f} seconds. Estimated time remaining: {estimated_time_remaining:.2f} seconds.\")\n",
    "\n",
    "# Final output\n",
    "print(f\"Total number of patients processed: {total_patients_processed}\")\n",
    "print(f\"Total number of pregnancies processed: {total_pregnancies}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3de59ade2ee4eabf8d6554090db31bdd94608df00f05391c2d316a7da62ee3f6"
  },
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
